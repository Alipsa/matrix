package se.alipsa.matrix.avro

import groovy.transform.CompileStatic
import org.apache.avro.Conversions
import org.apache.avro.LogicalTypes
import org.apache.avro.Schema
import org.apache.avro.UnresolvedUnionException
import org.apache.avro.file.DataFileWriter
import org.apache.avro.generic.GenericData
import org.apache.avro.generic.GenericDatumWriter
import org.apache.avro.generic.GenericFixed
import org.apache.avro.generic.GenericRecord
import se.alipsa.matrix.core.Matrix

import java.math.RoundingMode
import java.nio.ByteBuffer
import java.nio.file.Path
import java.sql.Time
import java.time.*

@CompileStatic
class MatrixAvroWriter {

  /** Write to a File */
  static void write(Matrix matrix, File file, boolean inferPrecisionAndScale = false) {
    if (matrix == null) {
      throw new IllegalArgumentException("Matrix cannot be null")
    }
    if (matrix.columnCount() == 0) {
      throw new IllegalArgumentException("Matrix must have at least one column")
    }
    Schema schema = buildSchema(matrix, inferPrecisionAndScale)
    DataFileWriter<GenericRecord> dfw = new DataFileWriter<>(new GenericDatumWriter<GenericRecord>(schema))
    dfw.create(schema, file)
    try {
      writeRows(matrix, dfw, schema) // removed unused inferPrecisionAndScale
    } finally {
      dfw.close()
    }
  }

  /** Write to a Path */
  static void write(Matrix matrix, Path path, boolean inferPrecisionAndScale = false) {
    if (matrix == null) {
      throw new IllegalArgumentException("Matrix cannot be null")
    }
    write(matrix, path.toFile(), inferPrecisionAndScale)
  }

  /**
   * Write to a byte array in Avro format.
   *
   * @param matrix the Matrix to write
   * @param inferPrecisionAndScale whether to infer precision and scale for BigDecimal columns
   * @return byte array containing Avro data
   */
  static byte[] writeBytes(Matrix matrix, boolean inferPrecisionAndScale = false) {
    if (matrix == null) {
      throw new IllegalArgumentException("Matrix cannot be null")
    }
    if (matrix.columnCount() == 0) {
      throw new IllegalArgumentException("Matrix must have at least one column")
    }
    ByteArrayOutputStream baos = new ByteArrayOutputStream()
    Schema schema = buildSchema(matrix, inferPrecisionAndScale)
    DataFileWriter<GenericRecord> dfw = new DataFileWriter<>(new GenericDatumWriter<GenericRecord>(schema))
    dfw.create(schema, baos)
    try {
      writeRows(matrix, dfw, schema)
    } finally {
      dfw.close()
    }
    return baos.toByteArray()
  }

  // ----------------------------------------------------------------------
  // Schema building
  // ----------------------------------------------------------------------

  static Schema buildSchema(Matrix matrix, boolean inferPrecisionAndScale) {
    Schema record = Schema.createRecord("MatrixSchema", "Generated by MatrixAvroWriter", "se.alipsa.matrix.avro", false)
    List<Schema.Field> fields = new ArrayList<>(matrix.columnCount())

    Map<String, int[]> decimalMeta = inferPrecisionAndScale ? inferDecimalPrecisionAndScale(matrix) : null

    for (String col : matrix.columnNames()) {
      Class<?> clazz = effectiveTypeForColumn(matrix, col)
      Schema fieldSchema

      if (clazz == List) {
        Class<?> elemClass = inferListElemClass(matrix, col)
        Schema elemSchema = toFieldSchema(elemClass, null)
        // allow null elements in arrays
        Schema nullableElem = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), elemSchema))
        fieldSchema = Schema.createArray(nullableElem)
      } else if (clazz == Map) {
        if (isRecordLikeColumn(matrix, col)) {
          // RECORD: fixed fields from the first non-null row
          // collect field names from the first non-null map
          Map first = null
          for (int r = 0; r < matrix.rowCount() && first == null; r++) {
            def v = matrix[r, col]
            if (v instanceof Map) first = (Map) v
          }
          def rec = Schema.createRecord(col + "_record", null, "se.alipsa.matrix.avro", false)
          List<Schema.Field> flds = new ArrayList<>()
          for (def k : first.keySet()) {
            def v = first.get(k)
            Class<?> vClazz = (v == null) ? String : v.getClass()
            Schema valueSchema = toFieldSchema(vClazz, null)
            // nullable union for each field
            Schema nullable = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), valueSchema))
            flds.add(new Schema.Field(k.toString(), nullable, null as String, (Object) null))
          }
          rec.setFields(flds)
          fieldSchema = rec
        } else {
          Class<?> valClass = inferMapValueClass(matrix, col)
          Schema valueSchema = toFieldSchema(valClass, null)
          Schema nullableValue = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), valueSchema))
          fieldSchema = Schema.createMap(nullableValue)
        }
      } else {
        fieldSchema = toFieldSchema(clazz, decimalMeta != null ? decimalMeta.get(col) : null)
      }
      Schema nullable = Schema.createUnion(Arrays.asList(Schema.create(Schema.Type.NULL), fieldSchema))
      fields.add(new Schema.Field(col, nullable, null as String, (Object) null))
    }

    record.setFields(fields)
    return record
  }

  private static Schema toFieldSchema(Class<?> clazz, int[] decimalMeta) {
    if (clazz == BigDecimal) {
      if (decimalMeta != null) {
        int precision = decimalMeta[0] > 0 ? decimalMeta[0] : 10
        int scale = decimalMeta[1] >= 0 ? decimalMeta[1] : 2
        Schema s = Schema.create(Schema.Type.BYTES)
        LogicalTypes.decimal(precision, scale).addToSchema(s)
        return s
      } else {
        return Schema.create(Schema.Type.DOUBLE) // fallback like Parquet writer
      }
    }

    if (clazz == String) return Schema.create(Schema.Type.STRING)
    if (clazz == Boolean || clazz == boolean.class) return Schema.create(Schema.Type.BOOLEAN)
    if (clazz == Integer || clazz == int.class) return Schema.create(Schema.Type.INT)
    if (clazz == Long || clazz == long.class || clazz == BigInteger) return Schema.create(Schema.Type.LONG)
    if (clazz == Float || clazz == float.class) return Schema.create(Schema.Type.FLOAT)
    if (clazz == Double || clazz == double.class) return Schema.create(Schema.Type.DOUBLE)
    if (clazz == byte[].class) return Schema.create(Schema.Type.BYTES)

    if (clazz == LocalDate || clazz == java.sql.Date) {
      Schema s = Schema.create(Schema.Type.INT)
      LogicalTypes.date().addToSchema(s)
      return s
    }
    if (clazz == LocalTime || clazz == Time) {
      Schema s = Schema.create(Schema.Type.INT)
      LogicalTypes.timeMillis().addToSchema(s)
      return s
    }
    if (clazz == Instant) {
      Schema s = Schema.create(Schema.Type.LONG)
      LogicalTypes.timestampMillis().addToSchema(s)
      return s
    }
    if (clazz == LocalDateTime) {
      Schema s = Schema.create(Schema.Type.LONG)
      LogicalTypes.localTimestampMicros().addToSchema(s)
      return s
    }
    if (clazz == Date) {
      Schema s = Schema.create(Schema.Type.LONG)
      LogicalTypes.timestampMillis().addToSchema(s)
      return s
    }
    if (clazz == UUID) {
      Schema s = Schema.create(Schema.Type.STRING)
      LogicalTypes.uuid().addToSchema(s)
      return s
    }

    // Fallback
    return Schema.create(Schema.Type.STRING)
  }

  static Map<String, int[]> inferDecimalPrecisionAndScale(Matrix matrix) {
    Map<String, int[]> meta = [:] as Map<String, int[]>
    for (String col : matrix.columnNames()) {
      if (matrix.type(col) == BigDecimal) {
        int maxPrecision = 0
        int maxScale = 0
        for (int r = 0; r < matrix.rowCount(); r++) {
          def v = matrix[r, col]
          if (v instanceof BigDecimal) {
            BigDecimal bd = (BigDecimal) v
            maxPrecision = Math.max(maxPrecision, bd.precision())
            maxScale = Math.max(maxScale, bd.scale())
          }
        }
        if (maxPrecision == 0) maxPrecision = 10
        if (maxScale < 0) maxScale = 0
        meta[col] = [maxPrecision, maxScale] as int[]
      }
    }
    return meta
  }

  // ----------------------------------------------------------------------
  // Row writing
  // ----------------------------------------------------------------------

  private static void writeRows(Matrix matrix, DataFileWriter<GenericRecord> dfw, Schema schema) {
    GenericData.Record rec = new GenericData.Record(schema)
    Conversions.DecimalConversion decConv = new Conversions.DecimalConversion()

    // Unwrap nullable unions to actual field schema
    Map<String, Schema> fieldSchemas = new LinkedHashMap<>()
    for (Schema.Field f : schema.getFields()) {
      Schema s = f.schema()
      if (s.getType() == Schema.Type.UNION) {
        for (Schema t : s.getTypes()) {
          if (t.getType() != Schema.Type.NULL) {
            s = t; break
          }
        }
      }
      fieldSchemas.put(f.name(), s)
    }

    List<String> cols = matrix.columnNames()
    int rows = matrix.rowCount()

    for (int r = 0; r < rows; r++) {
      for (String col : cols) {
        Object v = matrix[r, col]
        Schema fs = fieldSchemas.get(col)
        rec.put(col, toAvroValue(fs, v, decConv))
      }
      dfw.append(rec)
      rec = new GenericData.Record(schema) // fresh record per row
    }
  }

  private static Object toAvroValue(Schema fieldSchema, Object v, Conversions.DecimalConversion decConv) {
    if (v == null) return null

    // Handle UNIONs (including nested unions for array items and map values)
    if (fieldSchema.getType() == Schema.Type.UNION) {
      List<Schema> types = fieldSchema.getTypes()

      // Common case: ["null", T]
      if (types.size() == 2 && (types[0].getType() == Schema.Type.NULL || types[1].getType() == Schema.Type.NULL)) {
        Schema nonNull = (types[0].getType() == Schema.Type.NULL) ? types[1] : types[0]
        return (v == null) ? null : toAvroValue(nonNull, v, decConv)
      }

      // More general unions: pick the first compatible branch and serialize with it
      for (Schema branch : types) {
        if (branch.getType() == Schema.Type.NULL && v == null) return null
        if (branch.getType() == Schema.Type.NULL) continue
        if (isCompatible(branch, v)) {
          return toAvroValue(branch, v, decConv)
        }
      }

      // Could not resolve union — let Avro complain in a predictable way
      throw new UnresolvedUnionException(fieldSchema, v)
    }

    def lt = fieldSchema.getLogicalType()
    if (lt != null) {
      String name = lt.getName()
      switch (name) {
        case "date":
          if (v instanceof java.sql.Date) v = ((java.sql.Date) v).toLocalDate()
          if (v instanceof LocalDate) return (int) ((LocalDate) v).toEpochDay()
          break

        case "time-millis":
          if (v instanceof Time) v = ((Time) v).toLocalTime()
          if (v instanceof LocalTime) {
            int nanosMs = ((LocalTime) v).getNano().intdiv(1_000_000) // nanos -> millis
            long ms = ((LocalTime) v).toSecondOfDay() * 1000L + nanosMs
            return (int) ms
          }
          break

        case "local-timestamp-micros":
          if (v instanceof LocalDateTime) {
            int nanosUs = ((LocalDateTime) v).getNano().intdiv(1_000) // nanos -> micros
            long micros = ((LocalDateTime) v).toEpochSecond(ZoneOffset.UTC) * 1_000_000L + nanosUs
            return micros
          }
          break

        case "timestamp-millis":
          if (v instanceof Date) return ((Date) v).getTime()
          if (v instanceof Instant) return ((Instant) v).toEpochMilli()
          if (v instanceof LocalDateTime) {
            long ms = ((LocalDateTime) v)
                .toInstant(ZoneOffset.systemDefault().getRules().getOffset((LocalDateTime) v))
                .toEpochMilli()
            return ms
          }
          break

        case "local-timestamp-millis":
          if (v instanceof LocalDateTime) {
            int nanosMs = ((LocalDateTime) v).getNano().intdiv(1_000_000) // nanos -> millis
            long ms = ((LocalDateTime) v).toEpochSecond(ZoneOffset.UTC) * 1_000L + nanosMs
            return ms
          }
          break

        case "uuid":
          return v.toString()

        case "decimal":
          if (v instanceof BigDecimal) {
            LogicalTypes.Decimal dec = (LogicalTypes.Decimal) lt
            return decConv.toBytes((BigDecimal) v, fieldSchema, dec)
          } else if (v instanceof Double || v instanceof Float) {
            LogicalTypes.Decimal dec = (LogicalTypes.Decimal) lt
            BigDecimal bd = new BigDecimal(((Number) v).toString())
                .setScale(dec.getScale(), RoundingMode.HALF_UP)
            return decConv.toBytes(bd, fieldSchema, dec)
          }
          break
      }
    }

    // Primitive fallback based on schema type
    switch (fieldSchema.getType()) {
      case Schema.Type.STRING:
        return v.toString()
      case Schema.Type.BOOLEAN:
        return (Boolean) v
      case Schema.Type.INT:
        if (v instanceof Number) return ((Number) v).intValue()
        break
      case Schema.Type.LONG:
        if (v instanceof BigInteger) return ((BigInteger) v).longValue()
        if (v instanceof Number) return ((Number) v).longValue()
        if (v instanceof Date) return ((Date) v).time
        if (v instanceof Instant) return ((Instant) v).toEpochMilli()
        break
      case Schema.Type.FLOAT:
        if (v instanceof Number) return ((Number) v).floatValue()
        break
      case Schema.Type.DOUBLE:
        if (v instanceof BigDecimal) return ((BigDecimal) v).doubleValue()
        if (v instanceof Number) return ((Number) v).doubleValue()
        break
      case Schema.Type.BYTES:
        if (v instanceof byte[]) return ByteBuffer.wrap((byte[]) v)
        if (v instanceof ByteBuffer) return v
        if (v instanceof BigDecimal) {
          // fallback: unscaled bytes (only if schema is plain BYTES w/o decimal)
          return ByteBuffer.wrap(((BigDecimal) v).unscaledValue().toByteArray())
        }
        break
      case Schema.Type.ARRAY:
        Schema elem = fieldSchema.getElementType()
        List input = (List) v
        List out = new ArrayList( input == null ? 0 : input.size() )
        if ( input != null ) {
          for (def e: input ) out.add(toAvroValue(elem, e, decConv))
        }
        return out

      case Schema.Type.MAP:
        Schema vs = fieldSchema.getValueType()
        Map inMap = (Map) v
        Map<String, Object> outMap = new LinkedHashMap<>()
        if (inMap != null) {
          for (def e : inMap.entrySet()) {
            outMap.put(e.key?.toString(), toAvroValue(vs, e.value, decConv))
          }
        }
        return outMap

      case Schema.Type.RECORD:
        GenericData.Record gr = new GenericData.Record(fieldSchema)
        Map inRec = (Map) v
        for (Schema.Field f : fieldSchema.getFields()) {
          def fv = (inRec == null) ? null : inRec.get(f.name())
          // unwrap nullable union in field
          Schema fs = f.schema()
          if (fs.getType() == Schema.Type.UNION) {
            for (Schema t : fs.getTypes()) {
              if (t.getType() != Schema.Type.NULL) {
                fs = t; break
              }
            }
          }
          gr.put(f.name(), toAvroValue(fs, fv, decConv))
        }
        return gr
    }

    // Last resort
    return v.toString()
  }

  private static Class<?> effectiveTypeForColumn(Matrix matrix, String col) {
    Class<?> declared = matrix.type(col)
    if (declared != Object && declared != Number) {
      // Normalize BigInteger to Long
      if (declared == BigInteger) return Long
      return declared
    }

    boolean sawBigDecimal = false
    boolean sawFloat = false
    boolean sawIntegral = false
    boolean needsLong = false

    Class<?> concrete = null
    for (int r = 0; r < matrix.rowCount(); r++) {
      Object v = matrix[r, col]
      if (v == null) continue
      concrete = (concrete == null) ? v.getClass() : concrete

      if (v instanceof BigDecimal) {
        sawBigDecimal = true
      } else if (v instanceof Float || v instanceof Double) {
        sawFloat = true
      } else if (v instanceof Byte || v instanceof Short || v instanceof Integer
          || v instanceof Long || v instanceof BigInteger) {
        sawIntegral = true
        long lv = (v instanceof BigInteger) ? ((BigInteger) v).longValue() : ((Number) v).longValue()
        if (lv < Integer.MIN_VALUE || lv > Integer.MAX_VALUE || v instanceof Long || v instanceof BigInteger) {
          needsLong = true
        }
      } else if (v instanceof String || v instanceof Boolean || v instanceof byte[]
          || v instanceof java.sql.Date || v instanceof Time || v instanceof Date
          || v instanceof LocalDate || v instanceof LocalTime
          || v instanceof Instant || v instanceof LocalDateTime
          || v instanceof UUID) {
        // a specific non-numeric type — return that exact class
        return v.getClass()
      } else if (v instanceof List) {
        return List
      } else if (v instanceof Map) {
        return Map
      } else {
        // unknown custom type: fall back to String
        return String
      }
    }

    if (sawBigDecimal) return BigDecimal
    if (sawFloat) return Double
    if (sawIntegral) return needsLong ? Long : Integer

    // all nulls
    return String
  }

  // Decide if a Map column should be encoded as Avro RECORD (fixed field set) or MAP (free-form keys)
  private static boolean isRecordLikeColumn(Matrix matrix, String col) {
    Set<String> firstKeys = null
    for (int r = 0; r < matrix.rowCount(); r++) {
      def v = matrix[r, col]
      if (!(v instanceof Map)) continue
      Set<String> keys = new LinkedHashSet<>(((Map) v).keySet().collect { it?.toString() })
      if (firstKeys == null) {
        firstKeys = keys
      } else if (!firstKeys.equals(keys)) {
        return false // varying key sets → use MAP
      }
    }
    return firstKeys != null // fixed key set seen → treat as RECORD
  }

  // For a LIST column: infer the first non-null element class (kept simple for tests)
  private static Class<?> inferListElemClass(Matrix matrix, String col) {
    for (int r = 0; r < matrix.rowCount(); r++) {
      def v = matrix[r, col]
      if (v instanceof List) {
        List lst = (List) v
        for (def e : lst) {
          if (e != null) return e.getClass()
        }
      }
    }
    return String // fallback if empty lists/nulls only
  }

  // For a MAP column (as MAP): infer the first non-null value class
  private static Class<?> inferMapValueClass(Matrix matrix, String col) {
    for (int r = 0; r < matrix.rowCount(); r++) {
      def v = matrix[r, col]
      if (v instanceof Map) {
        Map m = (Map) v
        for (def e : m.values()) {
          if (e != null) return e.getClass()
        }
      }
    }
    return String
  }

  private static boolean isCompatible(Schema s, Object v) {
    if (v == null) return s.getType() == Schema.Type.NULL
    switch (s.getType()) {
      case Schema.Type.STRING: return true // we'll toString() later
      case Schema.Type.BOOLEAN: return v instanceof Boolean
      case Schema.Type.INT: return v instanceof Byte || v instanceof Short || v instanceof Integer
      case Schema.Type.LONG: return v instanceof Number // includes Integer/Long/BigInteger
      case Schema.Type.FLOAT: return v instanceof Number
      case Schema.Type.DOUBLE: return v instanceof Number || v instanceof BigDecimal
      case Schema.Type.BYTES: return (v instanceof byte[]) || (v instanceof ByteBuffer) || (v instanceof BigDecimal)
      case Schema.Type.ARRAY: return v instanceof List
      case Schema.Type.MAP: return v instanceof Map
      case Schema.Type.RECORD: return (v instanceof Map) || (v instanceof GenericRecord)
      case Schema.Type.FIXED: return v instanceof GenericFixed
      default: return false
    }
  }
}
