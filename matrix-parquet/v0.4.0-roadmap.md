# matrix-parquet v0.4.0 Roadmap

This roadmap outlines improvements and bugfixes identified through code review of the matrix-parquet module.

## Overview

The matrix-parquet module provides Parquet file format support for the Matrix library. The module was significantly refactored in v0.4.0 to remove the parquet-carpet dependency and implement native Parquet reading/writing with support for nested structures.

## Bug Fixes

### 1. Time precision schema/implementation mismatch (COMPLETED)
The schema declared time fields as MILLIS but the implementation wrote in different units:
- LocalDateTime: schema declared MILLIS, code wrote microseconds
- LocalTime: schema declared MILLIS, code wrote seconds

This inconsistency could cause issues when reading files with other Parquet tools.

**Resolution:**
- Changed timestamp schema from MILLIS to MICROS (matches actual microsecond storage)
- Changed Time handling to use milliseconds (write: `toNanoOfDay() / 1_000_000L`, read: `ofNanoOfDay(millis * 1_000_000L)`)
- Added proper handling for `java.sql.Timestamp` type in reader
- Tests verified with `./gradlew :matrix-parquet:test`

1.1 [x] Audit time precision handling in `MatrixParquetWriter._writeInternal()` at lines 514-516
1.2 [x] Align schema declaration with actual write precision (MICROS for timestamps, MILLIS for time)
1.3 [x] Update `MatrixParquetReader.readValue()` time handling to match the chosen precision
1.4 [x] Add dedicated test for time precision round-trip verification (`testTimePrecisionRoundTrip`)

### 2. Remove debug println statement
A debug println statement remains in production code.

2.1 [x] Remove println at `MatrixParquetWriter.groovy:109` or convert to proper SLF4J logging

## Code Quality Improvements

### 3. Add @CompileStatic to MatrixParquetReader (COMPLETED)
`MatrixParquetWriter` uses `@CompileStatic` but `MatrixParquetReader` did not, creating inconsistency.

**Resolution:**
- Added `@CompileStatic` annotation to `MatrixParquetReader` class
- No type inference issues arose - compilation and all tests passed
- Tests verified with `./gradlew :matrix-parquet:test`

3.1 [x] Add `@CompileStatic` annotation to `MatrixParquetReader` class
3.2 [x] Fix any type inference issues that arise from static compilation (none required)

### 4. Add input validation (COMPLETED)
Neither writer nor reader validated input parameters. Other modules like matrix-csv have `validateMatrix()` methods.

**Resolution:**
- Added `validateInput()` method to `MatrixParquetWriter` checking for null matrix, empty matrix, and null file
- Added `validateFile()` method to `MatrixParquetReader` checking for null file, non-existent file, and directory
- Added validation tests `testWriterValidation()` and `testReaderValidation()`
- Tests verified with `./gradlew :matrix-parquet:test`

4.1 [x] Add null check for Matrix parameter in `MatrixParquetWriter.write()` methods
4.2 [x] Add validation for empty matrix (no columns) before writing
4.3 [x] Add null check for File parameter in `MatrixParquetReader.read()` methods
4.4 [x] Add file existence validation in reader

### 5. Extract magic strings to constants (COMPLETED)
Multiple magic string values were used throughout the code:
- `"element"`, `"key"`, `"value"`, `"list"`, `"key_value"` (Parquet schema field names)
- `"matrix.columnTypes"` (metadata key)

**Resolution:**
- Added constants to `MatrixParquetWriter`: `METADATA_COLUMN_TYPES`, `FIELD_ELEMENT`, `FIELD_KEY`, `FIELD_VALUE`, `FIELD_LIST`, `FIELD_KEY_VALUE`
- Added constants to `MatrixParquetReader`: `METADATA_COLUMN_TYPES`, `FIELD_LIST`, `FIELD_KEY_VALUE`
- Replaced all magic string usages with constants
- Tests verified with `./gradlew :matrix-parquet:test`

5.1 [x] Create constants for Parquet schema field names
5.2 [x] Create constant for metadata key `"matrix.columnTypes"`

### 6. Add class-level documentation (COMPLETED)
Both main classes lacked class-level GroovyDoc comments.

**Resolution:**
- Added comprehensive GroovyDoc to `MatrixParquetWriter` covering usage examples, BigDecimal precision control, supported data types, and metadata
- Added comprehensive GroovyDoc to `MatrixParquetReader` covering usage examples, type preservation, external file support, and limitations
- Tests verified with `./gradlew :matrix-parquet:test`

6.1 [x] Add class-level GroovyDoc to `MatrixParquetWriter` describing its purpose and usage
6.2 [x] Add class-level GroovyDoc to `MatrixParquetReader` describing its purpose and usage

## Feature Enhancements

### 7. Add timezone support for timestamps (COMPLETED)
Previously all timestamps used `ZoneId.systemDefault()`, which could cause data loss when reading files written on systems with different timezones.

**Resolution:**
- Added `write(Matrix, File, ZoneId)` method to `MatrixParquetWriter`
- Added `read(File, ZoneId)` and `read(File, String, ZoneId)` methods to `MatrixParquetReader`
- Used thread-local pattern to pass timezone through call stack without changing internal method signatures
- Updated class-level GroovyDoc with timezone handling examples
- Added `testTimezoneHandling()` test verifying round-trip with different timezones and null validation
- Tests verified with `./gradlew :matrix-parquet:test`

7.1 [x] Add optional timezone parameter to writer methods
7.2 [x] Add optional timezone parameter to reader methods
7.3 [x] Document timezone handling behavior in GroovyDoc
7.4 [x] Add test for timezone-aware timestamp handling

### 8. Improve error messages
Error handling exists but messages could be more descriptive.

8.1 [ ] Improve `IllegalArgumentException` message at line 530 (list field type error)
8.2 [ ] Improve `IllegalArgumentException` message at line 548 (map field type error)
8.3 [ ] Add descriptive error when precision overflow occurs during BigDecimal write

## Performance Optimizations

### 9. Cache reflection metadata for struct handling
The `buildStructType()` method uses Introspector on every call without caching PropertyDescriptors, which can be slow for large matrices with complex objects.

9.1 [ ] Consider caching PropertyDescriptor results for repeated struct type inference
9.2 [ ] Cache `Class.forName()` results during reading (line 97)

## Documentation Improvements

### 10. Document known limitations
The readme.md could benefit from documenting edge cases and limitations.

10.1 [ ] Document that Matrix is an in-memory structure (no streaming support)
10.2 [ ] Document timezone handling behavior
10.3 [ ] Document BigDecimal precision/scale requirements
10.4 [ ] Document nested structure support and limitations

## Test Coverage Improvements

### 11. Add edge case tests

11.1 [ ] Add test for empty Matrix write/read round-trip
11.2 [ ] Add test for Matrix with only null values in a column
11.3 [ ] Add test for special characters in column names
11.4 [ ] Add test for very large BigDecimal values (near precision limits)

## Priority Order

**High Priority (Bug Fixes):**
1. Time precision mismatch (#1)
2. Remove debug println (#2)

**Medium Priority (Code Quality):**
3. Add @CompileStatic to reader (#3)
4. Input validation (#4)
5. Error message improvements (#8)

**Lower Priority (Enhancements):**
6. Extract constants (#5)
7. Class-level documentation (#6)
8. Timezone support (#7)
9. Performance optimizations (#9)
10. Documentation improvements (#10)
11. Additional test coverage (#11)

## Notes

- The module targets JDK 21 maximum due to Hadoop 3.4.x compatibility constraints
- Recent v0.4.0 removed parquet-carpet dependency in favor of native implementation
- Nested structure support (LIST, MAP, STRUCT) was added in v0.4.0
- BigDecimal precision/scale handling was significantly improved with explicit control options
